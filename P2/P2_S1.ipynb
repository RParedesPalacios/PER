{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necesarios\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST \n",
    "\n",
    "MNIST es un dataset clásico de clasificación de dígitos manuscritos (0..9). Los dígitos están representados mediante imágenes de 28x28 píxels en escala de grises. Los mejores resultados en este dataset se consiguen mediante redes neuronales convolucionales. Sin embargo nosotros vamos a emplear otro tipos de clasificadores vistos en clase. En concreto aquellos basados en árboles y distancias.\n",
    "\n",
    "Por otro lado vamos a realizar un diseño del experimento de manera adecuada empleando conjuntos de validación para poder estimar los mejores hiperparámetros. El conjunto de datos de test sólo lo emplearemos para realizar la última clasificación y reportar resultados.\n",
    "\n",
    "En esta primera práctica vamos a entrenar clasificadores basados en árboles de decisión sobre este dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre vamos a echar un vistazo a la descripción de este dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist.DESCR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los campos \"data\" y \"target\" se leen por defecto como una tabla de pandas. Dejar los datos en pandas puede tener alguna ventaja como por ejemplo que las características tienen un nombre asociado. No sería un problema continuar con llamadas a funciones sklearn con estos tipos de datos, pero si queremos aplicar alguna transformación con numpy lo ideal es convertirlos a numpy. Convertimos los datos y targets a numpy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist.data.shape)\n",
    "print(mnist.target.shape)\n",
    "\n",
    "data = mnist.data\n",
    "targets = mnist.target \n",
    "\n",
    "print(type(data))\n",
    "print(type(targets))\n",
    "\n",
    "#-------\n",
    "\n",
    "targets=targets.to_numpy()\n",
    "targets=np.int8(targets)\n",
    "\n",
    "data=data.to_numpy()\n",
    "data=np.float32(data)\n",
    "\n",
    "print(type(data))\n",
    "print(type(targets))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos por ejemplo la imagen promedio de algunas clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "clase=7\n",
    "m=np.mean(data[targets==clase],axis=0)\n",
    "m=np.reshape(m,(28,28))\n",
    "\n",
    "plt.imshow(m, cmap=plt.cm.gray_r, interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de los datos\n",
    "\n",
    "Vamos a partir los datos en tres conjuntos: training, validation y test. Con un 80%, 10% y 10% respectivamente. \n",
    "\n",
    "Emplearemos el conjunto de training para aprender los parámetros del modelos, el conjunto de validation para escoger los mejores hiperparámetros. Finalmente reportaremos el resultado final sobre el conjunto de test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1**  \n",
    "\n",
    "Realiza la partición de los datos en las particiones definidas (80%,10%,10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar partición de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 2**   \n",
    "\n",
    "Define un clasificador de tipo árbol de decisión. Varía el parámetro \"max_depth\" y quédate con aquel que mejor resultado se obtenga con los datos de validación. Finalmente obten el resultado sobre los datos de test con dicho mejor parámetro. Este último clasificador con el mejor parámetro se debería entrenar con todos los datos (training+validación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar mejor parámetro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener clasificador con mejor parámetro y acierto sobre test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 3**   \n",
    "\n",
    "Prueba otros parámetros del DecisionTreeClassifier que mejoren la tasa de acierto. En cualquier caso la selección de estos parámetros debe seguir el protocolo de experimentación antes expuesto. Esto es, escoger el mejor parámetro con datos de validación y reportar resultados con los datos de test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
